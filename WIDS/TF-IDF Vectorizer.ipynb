{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bulgarian-federal",
   "metadata": {},
   "source": [
    "### Format the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.core.display as di\n",
    "\n",
    "di.display_html(\"\"\"\n",
    "$('<style>.code_cell { margin-bottom: 80px !important;}</style>').appendTo('head');\n",
    "\"\"\", raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-respondent",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# external imports\n",
    "sys.path.append(\"../\")\n",
    "from YouReader.Reader import Reader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "# pandas settings\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('max_rows', None)\n",
    "\n",
    "# Constants\n",
    "TOKEN_PATTERN = r\"[^\\s]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-member",
   "metadata": {},
   "source": [
    "### Create Stemmer TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnowballStemmer Override for TfidfVectorizer\n",
    "# referenced from https://stackoverflow.com/questions/36182502/add-stemming-support-to-countvectorizer-sklearn\n",
    "\n",
    "english_stemmer = SnowballStemmer(\"english\")\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super().build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "stem_vectorizer = StemmedTfidfVectorizer(min_df=10, max_df=.75, stop_words=\"english\", ngram_range=(1,1), token_pattern=TOKEN_PATTERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-melbourne",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-fraud",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "count = reader.load_captions(\"../data/dataset.json\")\n",
    "df = reader.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-support",
   "metadata": {},
   "source": [
    "### Generate a template for generating the matrix (tokenizes terms)\n",
    "* fit() helps us generate a list of unique terms\n",
    "* creates a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate vectorizer template (skip to below if already generated)\n",
    "fit_vectorizer = stem_vectorizer.fit(df[\"clean\"])\n",
    "print(f\"There are {len(fit_vectorizer.vocabulary_)} unique terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run if you've saved the model\n",
    "with open(\"model/idf_fit_vectorizer.pkl\", \"rb\") as idf_fit_file:\n",
    "    fit_vectorizer = pickle.load(idf_fit_file)\n",
    "    \n",
    "print(f\"There are {len(fit_vectorizer.vocabulary_)} unique terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-faculty",
   "metadata": {},
   "source": [
    "### Generate training and testing sets\n",
    "* won't go too much into detail\n",
    "* here we are using stratified sampling to generate test and training datasets\n",
    "* 1/10 for testing, 9/10 for training\n",
    "* better to use k-fold cross validation or leave one out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training and testing sets (skip if already saved to pickle)\n",
    "all_keys = list(df.index.values)\n",
    "subjects = df[\"subject\"].unique()\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "train_data = []\n",
    "train_labels = []\n",
    "fold = 10\n",
    "\n",
    "# partition testing dataset to be 1/10, and training dataset to be 9/10 of original\n",
    "for subject in subjects:\n",
    "    subject_keys = [key for key in all_keys if df.loc[key][\"subject\"] == subject]\n",
    "    subject_clean = [df.loc[key][\"clean\"] for key in subject_keys]\n",
    "    subject_subject = [df.loc[key][\"subject\"] for key in subject_keys]\n",
    "    \n",
    "    test_size = 200 // fold\n",
    "    test_data.extend(subject_clean[:test_size])\n",
    "    test_labels.extend(subject_subject[:test_size])\n",
    "    train_data.extend(subject_clean[test_size:])\n",
    "    train_labels.extend(subject_subject[test_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-tamil",
   "metadata": {},
   "source": [
    "### Transform to training vector and testing vector to sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sparse matrix (skip if already saved as pickle)\n",
    "train_transform = fit_vectorizer.transform(train_data)\n",
    "test_transform = fit_vectorizer.transform(test_data)\n",
    "\n",
    "print(train_transform.shape)\n",
    "print(test_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run if you've saved the model\n",
    "with open(\"model/train_transform.pkl\", \"rb\") as train_transform_file:\n",
    "    train_transform = pickle.load(train_transform_file)\n",
    "\n",
    "with open(\"model/test_transform.pkl\", \"rb\") as test_transform_file:\n",
    "    test_transform = pickle.load(test_transform_file)\n",
    "    \n",
    "print(train_transform.shape)\n",
    "print(test_transform.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-edinburgh",
   "metadata": {},
   "source": [
    "### Save data into pickle (no need to regenerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/idf_fit_vectorizer.pkl\", \"wb\") as idf_fit_file:\n",
    "    pickle.dump(fit_vectorizer, idf_fit_file)\n",
    "\n",
    "with open(\"model/train_transform.pkl\", \"wb\") as train_transform_file:\n",
    "    pickle.dump(train_transform, train_transform_file)\n",
    "with open(\"model/train_labels.pkl\", \"wb\") as train_labels_file:\n",
    "    pickle.dump(train_labels, train_labels_file)\n",
    "\n",
    "with open(\"model/test_transform.pkl\", \"wb\") as test_transform_file:\n",
    "    pickle.dump(test_transform, test_transform_file)\n",
    "with open(\"model/test_labels.pkl\", \"wb\") as test_labels_file:\n",
    "    pickle.dump(test_labels, test_labels_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

machine
learning
part
to
what
you've
been
waiting
for
for
quite
some
time
I
can
tell
you
that
you
can
lock
to
work
in
data
science
without
knowing
statistics
and
probability
But
what
I
think
is
most
interesting
is
this
part
of
machine
learning
data
data
mining
and
this
kind
of
data
analysis
to
where
you're
not
just
learning
what's
happened
to
your
data
but
when
you
can
predict
what
is
going
to
happen
when
you
look
at
your
data
and
when
you
can
create
a
pattern
when
you
can
understand
the
pattern
behind
the
data
when
you
can
no
more
than
another
person
who
is
simply
looking
at
this
data
and
doesn't
know
this
methods
can
see
Today
we
will
start
with
mathematical
models
A
model
is
some
representation
of
your
process
Usually
at
the
beginning
you
don't
know
how
you
process
can
be
represented
The
models
can
be
very
very
different
And
without
having
a
little
bit
of
practice
of
knowledge
and
you
won't
even
be
able
to
start
or
you
won't
even
know
what
to
start
with
how
to
model
this
Who
knows
I
have
no
clue
But
the
simplest
model
that
we're
going
to
start
with
we're
going
to
model
the
process
with
a
straight
line
You
can
model
with
a
straight
line
You
can
model
with
a
polynomial
of
any
degree
with
a
cube
with
a
shape
of
a
human
with
a
color
with
just
about
anything
If
you
know
a
little
bit
about
your
data
a
little
bit
about
your
process
you
can
start
with
some
model
and
if
that
doesn't
work
then
you
will
understand
and
you
can
switch
This
is
the
phrase
that
I
liked
so
I
put
it
right
here
When
you
have
two
competing
theories
that
make
exactly
the
same
predictions
with
the
simpler
one
the
better
Do
not
try
to
over-complicate
Start
with
something
that
is
simple
What
types
types
of
model
for
revenue
mathematical
model
in
this
case
there
could
be
It
doesn't
mean
that
we
are
going
to
look
at
all
of
these
models
We're
going
to
look
at
the
simplest
But
then
if
you're
interested
you
can
always
learn
more
But
the
first
of
course
to
think
about
linear
versus
non-linear
linear
models
are
the
simplest
And
like
I
said
we're
going
to
start
with
linear
models
Black-box
versus
descriptive
models
Well
we
can
talk
about
it
a
lot
but
to
write
for
now
just
understand
blackbox
is
something
that
you
put
you
directly
and
you
don't
necessarily
know
what's
happening
inside
of
it
You
cannot
follow
every
step
of
it
Well
you
can
look
at
this
first
principle
versus
data
driven
models
You
will
not
understand
immediately
what
it
means
The
first
one
is
something
that
is
based
on
Theorems
formulas
theory
Something
that
you
know
really
well
The
example
right
here
says
for
example
Newton's
Law
You
take
the
formula
you
take
the
theorem
you
know
how
to
plug
you
apply
to
you
If
you
understand
how
to
apply
it
in
you
get
the
output
the
answer
to
your
question
Data
driven
models
are
absolutely
different
You
are
observing
your
data
and
you're
drawing
some
conclusions
on
the
basis
of
your
observation
And
so
on
You
can
always
bring
different
types
and
talking
about
different
types
of
model
The
more
you
work
the
more
you
know
of
the
smalls
We
are
going
to
work
on
data
driven
models
right
now
before
we
did
look
at
some
of
first
principles
models
Now
data
driven
models
But
there
are
two
types
right
here
that
we're
going
to
distinguish
supervised
and
unsupervised
learning
Sometimes
you
will
see
the
third
type
which
is
reinforcement
learning
which
is
well
we'll
just
describe
here
but
we're
not
going
to
go
over
it
later
on
The
supervised
models
first
Understand
what
does
it
mean
to
train
a
model
When
you
say
this
data
as
a
straight
line
So
if
I
know
something
about
this
data
if
I
know
something
that
happened
with
it
before
And
I
have
this
different
data
points
For
example
for
simplicity
audit
on
to
decline
I
will
say
well
it
looks
like
I
can
represent
it
with
this
line
or
with
some
line
With
some
straight
line
Training
A
model
is
finding
the
parameters
or
weights
for
this
model
If
I
say
that
I
will
try
to
use
a
straight
line
you
will
ask
me
to
write
an
equation
of
this
straight
line
Can
you
give
me
an
equation
of
straight
line
In
general
What
you
don't
have
to
type
it
there
just
seeing
MX
plus
B
Yeah
It
mx
plus
b
a
x
plus
B
Whatever
you
want
to
call
them
Great
But
this
is
just
my
model
I
don't
know
a
and
I
don't
know
If
I
analyze
my
data
If
I
look
at
the
points
x
y
then
I
can
learn
from
this
points
a
and
B
should
be
they're
not
going
to
be
exempt
They're
not
going
to
be
determined
as
you
would
do
in
your
fifth
grade
math
class
where
you
simply
computed
with
one
with
one
step
Just
by
solving
some
equations
You're
going
to
learn
in
you're
going
to
save
right
I
looked
and
it
seems
like
this
line
represents
my
data
with
the
smallest
error
So
this
is
what
the
training
process
is
going
to
lead
to
You
will
learn
some
parameters
for
widths
of
your
model
Supervised
learning
supervised
learning
You
are
looking
at
your
data
at
your
prior
data
You
are
teaching
your
model
you
are
training
your
model
You
are
telling
your
model
if
you
use
this
parameters
the
loss
or
the
error
For
now
we
will
talk
about
a
lot
but
you
can
think
about
air
for
now
is
going
to
be
such
If
you
change
your
parameters
a
little
bit
was
then
your
error
is
going
to
be
a
little
smaller
If
you
choose
your
parameters
this
way
your
error
is
going
to
be
greater
In
what
you're
trying
to
do
here
You
are
trying
to
minimize
the
loss
You're
trying
to
minimize
the
error
which
ever
the
set
of
parameters
minimizes
the
error
is
going
to
be
the
set
of
the
parameters
you're
going
to
use
for
your
model
Now
is
there
a
question
In
unsupervised
learning
In
unsupervised
learning
the
model
can
the
data
cannot
tell
you
Yes
If
you
use
this
parameters
the
error
is
such
If
you
use
this
the
error
is
such
You
don't
have
the
answers
to
your
questions
in
unsupervised
learning
So
you
are
learning
some
patterns
from
the
data
but
not
necessarily
you
know
what
is
correct
and
what
is
incorrect
unsupervised
learning
So
the
supervision
is
lost
In
this
case
In
reinforcement
learning
we
don't
necessarily
have
this
Yes
this
is
correct
If
I
have
this
input
the
output
is
that
we
don't
necessarily
have
this
But
there
is
something
or
some
conditions
to
where
the
machine
is
told
Alright
if
you
get
this
you're
getting
a
reward
So
we
do
have
some
sort
of
a
feedback
in
this
case
But
this
one
is
between
somewhat
supervised
and
unsupervised
So
we're
able
to
say
yeah
that's
Good
It's
called
every
word
signal
In
this
case
We're
going
to
start
with
supervised
learning
And
we
will
look
at
some
attributes
of
supervised
learning
What
we
need
to
know
before
we
start
actually
on
supervised
learning
Only
a
training
set
is
available
Like
we
said
before
In
a
supervised
learning
where
going
to
have
a
training
set
and
test
A
training
set
is
a
set
that
has
all
questions
answered
If
x
gives
this
white
is
that
And
I
don't
know
yet
what
my
test
and
set
is
going
to
be
It
may
come
later
So
I
don't
have
anything
to
test
my
data
on
right
now
What
do
I
do
in
this
case
We
take
this
training
set
and
divide
it
We
use
a
part
of
it
to
train
the
model
and
another
part
to
test
it
We
pretend
that
for
this
part
we
don't
have
answers
We
will
say
according
to
this
training
set
my
straight
line
For
example
I
said
we
will
start
with
the
straight
line
My
straight
line
is
going
to
be
such
And
then
I
will
say
I
use
it
on
the
test
set
I
am
going
to
have
such
error
And
this
error
is
going
to
be
how
far
these
points
from
the
test
and
set
or
from
my
prediction
It's
okay
if
you
don't
quite
understand
because
we
will
go
through
this
example
I
am
just
telling
you
what
is
testing
what
is
a
training
set
and
what
is
a
test
and
set
So
we
will
pretend
that
we
have
a
training
set
and
a
testing
set
This
simple
right
here
In
this
case
we're
simply
partition
in
the
set
into
two
training
intestine
And
then
we
don't
know
if
this
part
is
any
different
from
the
test
and
set
So
what
we
usually
do
we
use
a
K-fold
validation
For
example
two-thirds
is
going
to
be
used
for
training
and
1
third
for
testing
And
then
we
will
take
the
first
third
for
testing
the
rest
for
training
And
then
we
use
the
second
third
for
testing
in
the
respiratory
rabbit
correct
It
would
be
correct
to
say
that
we
use
this
for
training
and
the
rest
for
testing
process
wise
No
It's
also
common
to
use
the
live
one
out
We
use
only
one
data
point
for
testing
So
we
use
just
about
everything
of
the
training
set
of
the
set
that
we
have
for
training
and
will
leave
only
one
And
we're
going
to
test
the
performance
on
our
model
only
on
1
For
example
you
have
this
data
that
you
collected
from
the
survey
and
you're
asking
different
questions
What
you
want
you
want
to
see
if
GPE
GP
depends
on
some
other
attributes
of
the
test
So
in
that
case
you
can
run
your
statistical
tests
and
you
can
see
whether
it
does
or
doesn't
Now
in
this
case
when
we
come
to
some
machine
learning
techniques
to
prediction
what
we
have
we
have
data
for
example
for
CS101
students
We
know
all
the
attributes
and
GPS
for
all
the
students
Then
a
new
student
comes
We
don't
know
a
GP
of
the
student
Maybe
the
student
didn't
take
an
acos
As
a
few
Serra
yet
But
we
have
some
data
about
that
student
And
using
the
model
that
you
received
from
training
You
have
said
on
the
data
that
you
have
you
are
able
to
use
the
attributes
or
what
you
know
about
the
student
to
predict
the
GPA
of
that
student
Okay
so
this
is
what
we
are
going
to
face
We
have
some
data
that
is
available
And
when
a
new
point
comes
point
points
the
whole
set
we
will
be
able
to
make
predictions
Now
we
don't
know
we
have
never
seen
those
points
We
don't
know
whether
those
predictions
are
good
enough
Mythical
Now
usually
how
it's
done
is
you
are
those
before
We're
just
the
techniques
for
splitting
But
what
do
you
want
to
do
Normally
You
want
to
divide
your
fit
ahead
of
time
into
the
set
that
is
not
going
to
take
part
in
your
testing
at
all
We
will
see
we
will
explain
the
mistake
and
why
we
want
to
do
that
And
you
will
have
this
part
that
you
will
use
for
training
of
your
model
Some
part
How
it's
done
You
will
move
this
part
to
the
side
Don't
touch
it
with
the
remaining
part
But
this
validation
is
what
you're
going
to
test
your
model
on
This
is
the
whole
data
Leave
some
put
it
aside
Don't
touch
Train
your
model
on
some
subset
some
subset
of
this
training
set
And
in
this
in
this
set
you're
going
to
use
a
part
for
the
validation
It
could
believe
one
out
it
could
be
k-fold
In
this
case
it
is
5-fold
the
validation
Sometimes
it's
called
cross-validation
because
I'm
using
the
same
data
for
validation
and
for
the
training
So
in
this
case
it
is
a
fivefold
Normally
it's
just
called
K-fold
validation
If
you
use
the
leave
one
out
then
if
you
have
a
set
of
n
elements
it's
the
same
as
n
fold
validation
The
idea
is
this
thing
The
idea
is
the
same
right
here
Now
can
you
guess
why
would
you
leave
this
part
outside
And
you
will
not
allow
your
model
to
even
see
this
test
To
see
this
portion
is
identify
anomalies
and
kids
start
one
chunk
effect
So
datacenter
way
that
there's
not
a
good
try
You
made
some
point
in
what
do
you
mean
to
not
include
the
tests
in
your
dataset
Will
that
change
how
it
reacts
to
that
tests
later
on
Is
that
a
question
Yes
Yes
Because
part
of
it
is
already
an
answer
and
a
good
answer
That's
the
point
So
if
I
included
this
test
part
that
means
my
model
is
going
to
see
all
data
ahead
of
time
And
it's
going
to
be
looking
at
all
possible
variations
in
my
given
set
It's
going
to
learn
everything
that
is
there
But
whatever
comes
from
outside
later
after
this
process
is
completed
may
be
somewhat
different
from
what
we
learn
from
the
given
data
So
by
cutting
this
piece
and
not
introduced
it
into
the
model
I
don't
allow
my
model
to
see
everything
And
I
am
trying
to
see
how
my
model
is
going
to
perform
on
the
data
that
it
had
never
seen
before
If
it's
going
to
perform
really
poorly
compared
to
how
it
performed
on
the
data
that
it
had
seen
before
That
means
that
I
overtrained
the
data
over
trained
the
model
We
will
look
in
a
minute
What
exactly
it
means
It
means
I
learned
too
much
from
every
little
bit
It
means
that
there
were
anomalies
right
here
that
I
thought
were
normal
This
is
what
Richard
just
mentioned
There
were
anomalies
that
I
thought
maybe
I
should
account
for
those
Maybe
those
anomalies
were
somewhat
normal
immediate
those
switches
noise
outliers
that
were
presented
because
of
some
sort
of
pairs
Let's
say
Before
we
go
to
that
I
would
like
you
to
look
at
the
confusion
matrix
because
this
is
what
sometimes
help
us
to
understand
how
the
model
performs
Somehow
we
need
to
measure
the
performance
We
cannot
say
more
or
less
good
but
let
me
see
if
I
can
do
better
What
is
good
What
is
better
We
need
to
know
So
let's
look
at
the
confusion
matrix
I
think
it's
called
confusion
matrix
because
it
is
quite
confusing
to
be
honest
So
I
know
that
I
showed
this
matrix
last
quarter
And
then
one
question
on
the
exam
was
such
that
there
are
these
rows
and
columns
were
the
other
way
around
And
a
lot
of
students
didn't
realize
that
When
you're
looking
at
this
matrix
do
not
try
to
memorize
what
is
where
Try
to
understand
what's
inside
It
measures
the
performance
of
my
model
If
I
know
the
actual
answers
to
my
questions
for
example
where
it
working
on
prediction
And
we
simply
have
two
answers
yes
or
no
It
is
some
classifier
that
tells
me
for
example
who
were
looking
at
these
problems
before
whether
that
person
has
this
illness
or
sickness
or
not
Yes
or
no
to
in
this
in
this
case
we're
not
talking
about
this
that
linear
linear
model
but
we're
just
talking
about
the
classic
far
that
tells
me
glass
one
plus
two
Let's
say
one
is
the
is
the
other
one
is
known
So
that
actual
no
we
had
5060
cases
and
the
actual
Yes
we
had
a
105
cases
When
we
predicted
using
our
model
We
got
no
55
times
This
was
our
prediction
So
that's
the
correct
result
And
this
is
our
prediction
But
the
predicted
no
was
5550
Bills
corresponded
to
the
actual
note
So
that
was
correctly
predicted
This
Was
the
mistake
So
this
is
true
And
this
is
false
I
predicted
null
So
this
is
true
negative
And
this
is
false-negative
I
predicted
Yes
it
in
ten
cases
it
was
wrong
I
predicted
yes
when
it
should
have
been
known
And
we
predicted
a
100
correctly
We
predicted
a
yes
when
it
was
supposed
to
be
So
true
positives
100
I
answered
this
question
correctly
my
model
answered
it
correctly
False
We
predicted
Yes
when
actual
results
would
have
been
no
Right
Okay
Next
that's
actually
describes
what
we
just
talked
about
And
what
you
need
to
remember
is
this
value
is
recall
And
this
value
is
precision
Precision
it
predicts
how
often
it
is
correct
True
positives
Out
of
all
those
predicted
Yes
True
positives
Out
of
all
of
those
that
predicted
yes
Okay
Alright
I
don't
want
to
run
through
all
of
those
I
want
you
to
slowly
look
at
them
later
on
after
the
class
Ok
Slowly
slowly
Look
at
this
We
are
not
going
to
work
with
ROC
curves
but
they
also
measure
and
visualize
the
performance
of
binary
classifiers
We're
not
going
to
work
but
I
decided
to
put
them
right
here
So
you
know
how
they
look
at
lists
later
when
you
see
them
you
know
what
they
are
about
the
area
under
the
curve
that
also
shows
the
performance
of
your
algorithm
Multi-class
systems
You
can
see
this
examples
This
is
just
something
that's
so
you
know
the
names
We're
not
going
to
work
with
this
last
three
But
please
understand
this
matrix
very
well
I
don't
want
to
start
with
any
questions

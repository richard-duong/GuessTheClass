{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# external imports\n",
    "sys.path.append(\"../\")\n",
    "from YouReader.Reader import Reader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# pandas settings\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('max_rows', None)\n",
    "\n",
    "# Constants\n",
    "TOKEN_PATTERN = r\"[^\\s]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnowballStemmer Override for TfidfVectorizer\n",
    "# referenced from https://stackoverflow.com/questions/36182502/add-stemming-support-to-countvectorizer-sklearn\n",
    "\n",
    "english_stemmer = SnowballStemmer(\"english\")\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super().build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading Data from Save</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2600 captions from dataset.json\n",
      "\n",
      "\n",
      "subject\n",
      "BIOL    200\n",
      "BUS     200\n",
      "CHE     200\n",
      "CHEM    200\n",
      "CS      200\n",
      "ECON    200\n",
      "ENGL    200\n",
      "HIST    200\n",
      "MATH    200\n",
      "PHIL    200\n",
      "PHYS    200\n",
      "POSC    200\n",
      "PSYC    200\n",
      "Name: link, dtype: int64 \n",
      "\n",
      "\n",
      "This took 6.32 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "reader = Reader()\n",
    "count = reader.load_captions(\"../data/dataset.json\")\n",
    "df = reader.to_dataframe()\n",
    "subject_totals = df.groupby(\"subject\")[\"link\"].count()\n",
    "\n",
    "print(\"Loaded\", count, \"captions from dataset.json\\n\\n\")\n",
    "print(subject_totals, \"\\n\\n\")\n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load models if you've generated one before</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Fitted Stem Vectorizer Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Pickle Load fitted stem vectorizer model\n",
    "with open(\"../models/model1/stemidf_vectorizer.pkl\", \"rb\") as stemvec_file:\n",
    "    stem_fit_vectorizer = pickle.load(stemvec_file)\n",
    "    \n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Transformed Training Data and Labels</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Pickle Load transformed training model\n",
    "with open(\"../models/model1/stemidf_train_transform.pkl\", \"rb\") as train_transform_file:\n",
    "    train_transform = pickle.load(train_transform_file)\n",
    "\n",
    "# Pickle Load train labels\n",
    "with open(\"../models/model1/stemidf_train_labels.pkl\", \"rb\") as train_labels_file:\n",
    "    train_labels = pickle.load(train_labels_file)\n",
    "\n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Transformed Testing Data and Labels</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Pickle Load transformed testing model\n",
    "with open(\"../models/model1/stemidf_test_transform.pkl\", \"rb\") as test_transform_file:\n",
    "    test_transform = pickle.load(test_transform_file)\n",
    "    \n",
    "# Pickle Load test labels\n",
    "with open(\"../models/model1/stemidf_test_labels.pkl\", \"rb\") as test_labels_file:\n",
    "    test_labels = pickle.load(test_labels_file)\n",
    "\n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Skip down to KNN Analysis if you've already loaded all data!!!</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Vectorize and stem the corpus</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the custom stemming vectorizer\n",
    "stem_vectorizer = StemmedTfidfVectorizer(min_df=10, max_df=.7, stop_words=\"english\", token_pattern=TOKEN_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 116.59 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# fit data to all transcripts to generate vocabulary / features\n",
    "stem_fit_vectorizer = stem_vectorizer.fit(df[\"clean\"])\n",
    "\n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save Fitted Stem Vectorizer Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 0.04 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Pickle Save fitted stem vectorizer model\n",
    "with open(\"../models/model2/stemidf_vectorizer.pkl\", \"wb\") as stemvec_file:\n",
    "    pickle.dump(stem_fit_vectorizer, stemvec_file)\n",
    "    \n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transform Training and Test Datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of testing dataset is:  260\n",
      "Size of training dataset is:  2340\n",
      "This took 4.24 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# generate training and testing sets\n",
    "all_keys = list(df.index.values)\n",
    "subjects = df[\"subject\"].unique()\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "train_data = []\n",
    "train_labels = []\n",
    "fold = 10\n",
    "\n",
    "# partition testing dataset to be 1/10, and training dataset to be 9/10 of original\n",
    "for subject, total in zip(subjects, subject_totals):\n",
    "    subject_keys = [key for key in all_keys if df.loc[key][\"subject\"] == subject]\n",
    "    subject_clean = [df.loc[key][\"clean\"] for key in subject_keys]\n",
    "    subject_subject = [df.loc[key][\"subject\"] for key in subject_keys]\n",
    "    \n",
    "    test_size = total // fold\n",
    "    test_data.extend(subject_clean[:test_size])\n",
    "    test_labels.extend(subject_subject[:test_size])\n",
    "    train_data.extend(subject_clean[test_size:])\n",
    "    train_labels.extend(subject_subject[test_size:])\n",
    "\n",
    "    \n",
    "print(\"Size of testing dataset is: \", len(test_data))\n",
    "print(\"Size of training dataset is: \", len(train_data))    \n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset has the shape:  (2340, 13691)\n",
      "Testing dataset has the shape:  (260, 13691)\n",
      "This took 115.29 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# transforms datasets into feature vectors for ML analysis\n",
    "train_transform = stem_fit_vectorizer.transform(train_data)\n",
    "test_transform = stem_fit_vectorizer.transform(test_data)\n",
    "\n",
    "print(\"Training dataset has the shape: \", train_transform.shape)\n",
    "print(\"Testing dataset has the shape: \", test_transform.shape)\n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save Transformed Training Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Pickle Save transformed training model\n",
    "with open(\"../models/model2/stemidf_train_transform.pkl\", \"wb\") as train_transform_file:\n",
    "    pickle.dump(train_transform, train_transform_file)\n",
    "    \n",
    "# Pickle Save train labels\n",
    "with open(\"../models/model2/stemidf_train_labels.pkl\", \"wb\") as train_labels_file:\n",
    "    pickle.dump(train_labels, train_labels_file)\n",
    "\n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save Transformed Testing Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 0.01 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Pickle Save transformed testing model\n",
    "with open(\"../models/model2/stemidf_test_transform.pkl\", \"wb\") as test_transform_file:\n",
    "    pickle.dump(test_transform, test_transform_file)\n",
    "    \n",
    "# Pickle Save test labels\n",
    "with open(\"../models/model2/stemidf_test_labels.pkl\", \"wb\") as test_labels_file:\n",
    "    pickle.dump(test_labels, test_labels_file)\n",
    "\n",
    "print(\"This took\", \"{0:.2f}\".format(time.time() - start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>KNN Fitting and Prediction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=75)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generates and fits classifier to training dataset\n",
    "classifier = KNeighborsClassifier(n_neighbors=75)\n",
    "classifier.fit(train_transform, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BIOL</th>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "      <td>BIOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUS</th>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>ECON</td>\n",
       "      <td>BUS</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>BUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEM</th>\n",
       "      <td>CHEM</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS</th>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>BUS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECON</th>\n",
       "      <td>ECON</td>\n",
       "      <td>BUS</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>BUS</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "      <td>ECON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENGL</th>\n",
       "      <td>POSC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>POSC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>BUS</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>POSC</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>ENGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIST</th>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "      <td>HIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH</th>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "      <td>MATH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHIL</th>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>PHIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHYS</th>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>MATH</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>CHE</td>\n",
       "      <td>MATH</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>CHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSYC</th>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "      <td>PSYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHE</th>\n",
       "      <td>CHE</td>\n",
       "      <td>BUS</td>\n",
       "      <td>CHE</td>\n",
       "      <td>BUS</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>MATH</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>BUS</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>MATH</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>MATH</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POSC</th>\n",
       "      <td>POSC</td>\n",
       "      <td>POSC</td>\n",
       "      <td>POSC</td>\n",
       "      <td>BUS</td>\n",
       "      <td>POSC</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>CHE</td>\n",
       "      <td>POSC</td>\n",
       "      <td>POSC</td>\n",
       "      <td>POSC</td>\n",
       "      <td>POSC</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>POSC</td>\n",
       "      <td>POSC</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>POSC</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>BUS</td>\n",
       "      <td>POSC</td>\n",
       "      <td>HIST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9     10    11  \\\n",
       "BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL   \n",
       "BUS    BUS   BUS   BUS  ECON   BUS  PHIL   BUS   BUS   BUS   BUS   BUS   BUS   \n",
       "CHEM  CHEM  PHYS  CHEM  CHEM  CHEM  PHYS  CHEM  CHEM  CHEM  PHYS  PHIL  CHEM   \n",
       "CS      CS    CS    CS    CS    CS    CS    CS    CS    CS    CS    CS    CS   \n",
       "ECON  ECON   BUS  ECON  ECON  ECON  ECON  ECON  ECON  ECON  ECON  ECON  ECON   \n",
       "ENGL  POSC  PSYC  PSYC  ENGL  PSYC  ENGL  ENGL  POSC  PSYC  PSYC  PSYC  PSYC   \n",
       "HIST  HIST  HIST  HIST  HIST  HIST  HIST  HIST  HIST  HIST  PHIL  PHIL  HIST   \n",
       "MATH  MATH  MATH  MATH  MATH  MATH  MATH  MATH  MATH  MATH  MATH  MATH  MATH   \n",
       "PHIL  PHIL  PHIL  PHIL  PSYC  PHIL  PHIL  PHIL  PHIL  PHIL  PSYC  PHIL  PSYC   \n",
       "PHYS  PHYS  PHYS  PHYS  PHYS  PHYS  PHYS  PHYS  MATH  PHYS  PHYS  PHYS  PHYS   \n",
       "PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC   \n",
       "CHE    CHE   BUS   CHE   BUS   CHE  CHEM   CHE   CHE  MATH   CHE   CHE   BUS   \n",
       "POSC  POSC  POSC  POSC   BUS  POSC  PHIL   CHE  POSC  POSC  POSC  POSC  PHIL   \n",
       "\n",
       "        12    13    14    15    16    17    18    19  \n",
       "BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  BIOL  \n",
       "BUS    BUS   BUS   BUS   BUS   BUS   BUS   BUS   BUS  \n",
       "CHEM  CHEM  CHEM  CHEM  CHEM  CHEM  CHEM  CHEM  CHEM  \n",
       "CS      CS    CS    CS   BUS    CS    CS    CS    CS  \n",
       "ECON   BUS  ECON  ECON  ECON  ECON  ECON  ECON  ECON  \n",
       "ENGL  ENGL  ENGL   BUS  ENGL  ENGL  POSC  ENGL  ENGL  \n",
       "HIST  HIST  HIST  HIST  HIST  HIST  HIST  HIST  HIST  \n",
       "MATH  MATH  MATH  MATH  MATH  MATH  MATH  MATH  MATH  \n",
       "PHIL  PHIL  PHIL  PHIL  PHIL  PHIL  PHIL  PHIL  PHIL  \n",
       "PHYS  PHYS  PHYS  PHYS  PHYS   CHE  MATH  PHYS   CHE  \n",
       "PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  PSYC  \n",
       "CHE    CHE   CHE   CHE  MATH  CHEM  MATH   CHE   CHE  \n",
       "POSC  POSC  POSC  PHIL  POSC  PHIL   BUS  POSC  HIST  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    results[subject] = []\n",
    "\n",
    "for label, pred in zip(test_labels,prediction):\n",
    "    results[label].append(pred)\n",
    "    \n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(prediction, test_labels):\n",
    "    return sum([1 if subject1 == subject2 else 0 for subject1, subject2 in zip(prediction, test_labels)]) / len(prediction)\n",
    "\n",
    "def df_compare_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BIOL', 'BIOL', 'BIOL', 'BIOL', 'BIOL', 'BIOL', 'BIOL', 'BIOL',\n",
       "       'BIOL', 'BIOL', 'BIOL', 'BIOL', 'BIOL', 'BIOL', 'BIOL', 'BIOL',\n",
       "       'BIOL', 'BIOL', 'BIOL', 'BIOL', 'BUS', 'BUS', 'BUS', 'ECON', 'BUS',\n",
       "       'PHIL', 'BUS', 'BUS', 'BUS', 'BUS', 'BUS', 'BUS', 'BUS', 'BUS',\n",
       "       'BUS', 'BUS', 'BUS', 'BUS', 'BUS', 'BUS', 'CHEM', 'PHYS', 'CHEM',\n",
       "       'CHEM', 'CHEM', 'PHYS', 'CHEM', 'CHEM', 'CHEM', 'PHYS', 'PHIL',\n",
       "       'CHEM', 'CHEM', 'CHEM', 'CHEM', 'CHEM', 'CHEM', 'CHEM', 'CHEM',\n",
       "       'CHEM', 'CS', 'CS', 'CS', 'CS', 'CS', 'CS', 'CS', 'CS', 'CS', 'CS',\n",
       "       'CS', 'CS', 'CS', 'CS', 'CS', 'BUS', 'CS', 'CS', 'CS', 'CS',\n",
       "       'ECON', 'BUS', 'ECON', 'ECON', 'ECON', 'ECON', 'ECON', 'ECON',\n",
       "       'ECON', 'ECON', 'ECON', 'ECON', 'BUS', 'ECON', 'ECON', 'ECON',\n",
       "       'ECON', 'ECON', 'ECON', 'ECON', 'POSC', 'PSYC', 'PSYC', 'ENGL',\n",
       "       'PSYC', 'ENGL', 'ENGL', 'POSC', 'PSYC', 'PSYC', 'PSYC', 'PSYC',\n",
       "       'ENGL', 'ENGL', 'BUS', 'ENGL', 'ENGL', 'POSC', 'ENGL', 'ENGL',\n",
       "       'HIST', 'HIST', 'HIST', 'HIST', 'HIST', 'HIST', 'HIST', 'HIST',\n",
       "       'HIST', 'PHIL', 'PHIL', 'HIST', 'HIST', 'HIST', 'HIST', 'HIST',\n",
       "       'HIST', 'HIST', 'HIST', 'HIST', 'MATH', 'MATH', 'MATH', 'MATH',\n",
       "       'MATH', 'MATH', 'MATH', 'MATH', 'MATH', 'MATH', 'MATH', 'MATH',\n",
       "       'MATH', 'MATH', 'MATH', 'MATH', 'MATH', 'MATH', 'MATH', 'MATH',\n",
       "       'PHIL', 'PHIL', 'PHIL', 'PSYC', 'PHIL', 'PHIL', 'PHIL', 'PHIL',\n",
       "       'PHIL', 'PSYC', 'PHIL', 'PSYC', 'PHIL', 'PHIL', 'PHIL', 'PHIL',\n",
       "       'PHIL', 'PHIL', 'PHIL', 'PHIL', 'PHYS', 'PHYS', 'PHYS', 'PHYS',\n",
       "       'PHYS', 'PHYS', 'PHYS', 'MATH', 'PHYS', 'PHYS', 'PHYS', 'PHYS',\n",
       "       'PHYS', 'PHYS', 'PHYS', 'PHYS', 'CHE', 'MATH', 'PHYS', 'CHE',\n",
       "       'PSYC', 'PSYC', 'PSYC', 'PSYC', 'PSYC', 'PSYC', 'PSYC', 'PSYC',\n",
       "       'PSYC', 'PSYC', 'PSYC', 'PSYC', 'PSYC', 'PSYC', 'PSYC', 'PSYC',\n",
       "       'PSYC', 'PSYC', 'PSYC', 'PSYC', 'CHE', 'BUS', 'CHE', 'BUS', 'CHE',\n",
       "       'CHEM', 'CHE', 'CHE', 'MATH', 'CHE', 'CHE', 'BUS', 'CHE', 'CHE',\n",
       "       'CHE', 'MATH', 'CHEM', 'MATH', 'CHE', 'CHE', 'POSC', 'POSC',\n",
       "       'POSC', 'BUS', 'POSC', 'PHIL', 'CHE', 'POSC', 'POSC', 'POSC',\n",
       "       'POSC', 'PHIL', 'POSC', 'POSC', 'PHIL', 'POSC', 'PHIL', 'BUS',\n",
       "       'POSC', 'HIST'], dtype='<U4')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = classifier.predict(test_transform)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8269230769230769"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sum([1 if subject1 == subject2 else 0 for subject1, subject2 in zip(prediction, test_labels)]) / len(prediction)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CS'], dtype='<U4')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"computer science c python finance code code\"]\n",
    "sample_text_transform = stem_fit_vectorizer.transform(sample_text)\n",
    "classifier.predict(sample_text_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
